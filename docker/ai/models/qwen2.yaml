name: qwen2-1.5b
backend: llama-cpp
parameters:
  model: qwen2-1.5b-instruct-q4_k_m.gguf
  temperature: 0.7
  top_p: 0.9
  context_size: 4096
  threads: 4
  stop:
    - "<|im_end|>"
    - "<|endoftext|>"
