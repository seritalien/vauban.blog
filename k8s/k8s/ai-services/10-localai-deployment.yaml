apiVersion: apps/v1
kind: Deployment
metadata:
  name: localai
  namespace: ai-services
  labels:
    app: ai-services
    component: localai
spec:
  replicas: 1
  strategy:
    type: Recreate  # Single replica with persistent storage
  selector:
    matchLabels:
      app: ai-services
      component: localai
  template:
    metadata:
      labels:
        app: ai-services
        component: localai
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      terminationGracePeriodSeconds: 60
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      # Init container to download models if missing
      initContainers:
        - name: download-models
          image: busybox:1.36
          command:
            - /bin/sh
            - -c
            - |
              if [ ! -f /models/mistral-7b-instruct-v0.3.Q4_K_M.gguf ]; then
                echo "Models not found. Please download manually or use the download job."
                echo "See docs/ai-services/README.md for instructions."
                echo "Creating marker file to allow startup..."
                touch /models/.initialized
              else
                echo "Models already present:"
                ls -la /models/
              fi
          volumeMounts:
            - name: models
              mountPath: /models
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false
            capabilities:
              drop:
                - ALL
      containers:
        - name: localai
          image: localai/localai:v2.25.0-ffmpeg
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
          env:
            - name: THREADS
              value: "4"
            - name: CONTEXT_SIZE
              value: "4096"
            - name: MODELS_PATH
              value: /models
            - name: DEBUG
              value: "false"
            # Disable GPU if not available
            - name: BUILD_TYPE
              value: "generic"
          volumeMounts:
            - name: models
              mountPath: /models
            - name: model-configs
              mountPath: /models/mistral.yaml
              subPath: mistral.yaml
            - name: model-configs
              mountPath: /models/embeddings.yaml
              subPath: embeddings.yaml
            - name: model-configs
              mountPath: /models/phi3.yaml
              subPath: phi3.yaml
            - name: tmp
              mountPath: /tmp
          resources:
            requests:
              cpu: 500m
              memory: 2Gi
            limits:
              cpu: "4"
              memory: 8Gi
          livenessProbe:
            httpGet:
              path: /readyz
              port: 8080
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /readyz
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false  # LocalAI needs write access
            capabilities:
              drop:
                - ALL
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: localai-models
        - name: model-configs
          configMap:
            name: localai-models-config
        - name: tmp
          emptyDir: {}
